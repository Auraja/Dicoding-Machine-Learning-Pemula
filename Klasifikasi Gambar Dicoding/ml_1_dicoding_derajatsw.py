# -*- coding: utf-8 -*-
"""ML_1_Dicoding_DerajatSW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16TpAFZxJlfGCZCwxtj5qLQ0Hzlnf59Aj

owner : Derajat Salim Wibowo
email : derajat03@gmail.com
"""

print('Derajat Salim WIbowo')

# Commented out IPython magic to ensure Python compatibility.
#Memanggil libraryyyyyyyyyyyyyy
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import load_img, img_to_array
import zipfile,os
!pip install split-folders
import splitfolders
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

#Dataset berasal dari instruksi dicoding
!wget --no-check-certificate \
https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
-O /tmp/rockpaperscissors.zip

#Mengekstrak Dataset
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()
base_dir = '/tmp/rockpaperscissors/rps-cv-images'
os.listdir(base_dir)

#Membuat class supaya train berhenti ketika mencapai jumlah target
class Callback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.97):
      print("\n Traning berhenti karena akurasi diatas 97%!")
      self.model.stop_training = True
callbacks = Callback()

#Membagi dataset menjadi train dan validation
splitfolders.ratio(base_dir,seed=1337, ratio=(.6, .4), group_prefix=None)

#Membuat augmentasi gambar
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split=0.4)

#Membuat data generator Train
train_generator = train_datagen.flow_from_directory(
        base_dir,
        target_size=(150, 150), 
        shuffle=True,
        subset='training')

#Membuat data generator Validation
validation_generator = train_datagen.flow_from_directory(
        base_dir,
        target_size=(150, 150),
        shuffle=True,
        subset='validation')

#Membuat model sequential
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

#Membuat pelatihan model
train = model.fit(
        train_generator,
        steps_per_epoch=23,
        epochs=20,
        validation_data=validation_generator,
        validation_steps=6,
        verbose=2,
        callbacks=[callbacks])

#Membuat diagram garis untuk melihat history model 
plt.plot(train.history['accuracy'])
plt.plot(train.history['val_accuracy'])
plt.title('accuracy plot')
plt.ylabel('value')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(train.history['loss'])
plt.plot(train.history['val_loss'])
plt.title('loss plot')
plt.ylabel('value')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

#Memprediksi Gambar
uploaded = files.upload()
for fn in uploaded.keys():
 
  path = fn
  img = tf.keras.utils.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = tf.keras.utils.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  
  print(fn)
  if classes[0,0]==1:
    print('paper')
  elif classes[0,1]==1:
    print('rock')
  else:
    print('scissors')